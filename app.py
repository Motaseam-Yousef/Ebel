import os
from langchain import PromptTemplate, LLMChain
from langchain.prompts import PromptTemplate
from langchain.llms import openai,OpenAIChat
from gtts import gTTS
import streamlit as st
import numpy as np
from pydub import AudioSegment
from pydub.playback import play

import os
#os.environ["OPENAI_API_KEY"] = "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"

#os.environ["HUGGINGFACEHUB_API_TOKEN"] = "key"

#llm = OpenAI(temerature=0.9, model_name="text-davinci-003")

# Print the content
#print(response_dict["choices"][0]["message"]["content"])

st.title("ğŸ« Camel 911 ğŸ«")

prefix_messages = [{"role": "system", "content": "You are a Camels stuff assisst"}]

llm = OpenAIChat(model_name='gpt-3.5-turbo',
                openai_api_key="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",
                temperature=0,
                prefix_messages=prefix_messages,
                max_tokens = 500)

template = """{Ù…Ø¯Ø®Ù„}
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ù…Ø§Ù„ÙƒÙŠ ÙˆÙ‡ÙˆØ§Ø© Ø§Ù„Ø¥Ø¨Ù„ ØªØ¬ÙŠØ¨ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø­ÙŠØ§Ø© Ø§Ù„Ø¥Ø¨Ù„ ÙˆØµØ­Ø© Ø§Ù„Ø¥Ø¨Ù„ ÙˆØ¬Ù…ÙŠØ¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¥Ø¨Ù„ 
Ù„Ø§ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø£Ù† ØªØ®ØªØ±Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ùˆ ØªØªØ®ÙŠÙ„ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„ØªÙŠ Ù‚Ù…Øª Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„ÙŠÙ‡Ø§ 
ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¬Ù…ÙŠØ¹ Ø£Ø¬ÙˆØ¨ØªÙƒ Ù…Ø®ØªØµØ±Ø© ÙˆØ¨Ù„ØºØ© Ø³Ù‡Ù„Ø© ÙŠÙÙ‡Ù…Ù‡Ø§ Ø§Ù„Ø¬Ù…ÙŠØ¹
Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ù…Ø¯Ø®Ù„Ø§Øª Ù„ÙŠØ³Øª Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„Ø§ ØªÙ‚Ù… Ø¨Ø¥Ø®ØªØ±Ø§Ø¹ Ø£ÙŠ Ø¥Ø¬Ø§Ø¨Ø§Øª ÙÙ‚Ø· Ø£Ø¬Ø¨ "Ù„Ø§ Ø£Ø¹Ø±Ù Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø³Ø¤Ø§Ù„ Ø´Ø®Øµ Ù…Ø®ØªØµ "
ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¬Ù…ÙŠØ¹ Ø£Ø¬Ø§Ø¨Ø§ØªÙƒ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¯ÙˆÙ† Ø¥Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ ÙƒÙ„Ù…Ø© Ø¨Ù„ØºØ© Ø£Ø®Ø±Ù‰ 

Ø§Ø¹Ø±Ù Ø£Ù†:
Ø´Ø¯Ø§Ø¯ Ø§Ù„Ø®Ø±Ø¬ Ø£Ùˆ Ø§Ù„Ø®Ø±Ùƒ Ùˆ Ù‡Ùˆ Ù…Ø§ ÙŠÙˆØ¶Ø¹ Ø¹Ù„Ù‰ Ø¸Ù‡Ø± Ø§Ù„Ø¬Ù…Ù„ Ùˆ ÙŠÙˆØ¶Ø¹ Ø¨Ù‡ Ø§Ù„Ù…Ø¹Ø¯Ø§Øª Ø§Ù„Ø®ÙÙŠÙØ© Ø¨Ø§Ù„Ø³ÙØ±
"""

prompt = PromptTemplate(template=template, 
                        input_variables=["Ù…Ø¯Ø®Ù„"])

llm_chain = LLMChain(prompt=prompt, llm=llm)

Ù…Ø¯Ø®Ù„ = st.text_input("What's Your issue?!") 

response = llm_chain.run(Ù…Ø¯Ø®Ù„)
responseSound = gTTS(text=response, lang="ar", slow=False)
responseSound.save("res.mp3")

audio_file = open('res.mp3', 'rb')
audio_bytes = audio_file.read()

# Use Streamlit to play the audio file
st.write(response)
st.audio(audio_bytes, format='audio/mp3')

# Convert mp3 file to mp3
# audio = AudioSegment.from_mp3("res.mp3")
# audio.export("res.mp3", format="mp3")

# Open the mp3 file
# audio_file = open('res.mp3', 'rb')
# audio_bytes = audio_file.read()
# audio = AudioSegment.from_file("res.mp3")
# fast_audio = audio.speedup(playback_speed=2.0)

# st.audio(fast_audio.raw_data, format='audio/mp3')
# sample_rate = 44100  # 44100 samples per second
# seconds = 1  # Note duration of 2 seconds
# frequency_la = 500  # Our played note will be 440 Hz
# # Generate array with seconds*sample_rate steps, ranging between 0 and seconds
# t = np.linspace(0, seconds, seconds * sample_rate, False)
# # Generate a 440 Hz sine mp3e
# note_la = np.sin(frequency_la * t * 2 * np.pi)

# st.audio(note_la, sample_rate=sample_rate)

#if response: 
###    res= chain.run(result)

#    st.write(response_dict["choices"][0]["message"]["content"])
